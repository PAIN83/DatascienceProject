{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac44990a-c242-4014-a521-20d686899474",
   "metadata": {},
   "source": [
    "## üì¶ First, we bring in some tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05cf0b2-9b42-426e-8e6e-154287411b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9345a58-17d7-4d1f-926a-5076e11c7d22",
   "metadata": {},
   "source": [
    "### cv2: This is a tool (library) that helps the computer see pictures and videos.\n",
    "\n",
    "### numpy (np): NumPy helps us work with images as numbers.\n",
    "\n",
    "### Images are actually made of pixels, and pixels are numbers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec97b1c-5fe8-41d1-8054-a65b4d9227c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## def can(img):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96890a-d906-409e-833a-95045491cd4d",
   "metadata": {},
   "source": [
    "## We create a function(can) find the edge line like where the road lines are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561039b8-5bc5-478e-8b03-d826260bf8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  if img is None:  \n",
    "       ##  cap.release()    Stop the video\n",
    "       ##  cv2.destroyAllWindows()  Close all windows\n",
    "       ##  exit()   Exit the program    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623a3de-2edb-424b-8cb2-1d8906ca58ff",
   "metadata": {},
   "source": [
    "## If there's no image (video failed), we stop everything and close.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893c7d6e-38ee-47be-8da0-13d1ce59d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8b593-1f27-4e94-9c68-e704cd12f812",
   "metadata": {},
   "source": [
    "### üëâ This line converts a color image into a black-and-white image (also called a grayscale image).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23528e7-cd2a-4431-b064-83eb01bc7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cv2.cvtColor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94931528-2821-400b-8ef2-26667b172952",
   "metadata": {},
   "source": [
    "### This is a function from OpenCV (cv2) that changes the color format of an image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce981200-b819-4caa-915d-6f6252905dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  cv2.COLOR_BGR2GRAY "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac71d1d-1b5d-481a-bf3c-b10f133713a9",
   "metadata": {},
   "source": [
    "### ‚ÄúPlease remove the colors and give me a simple black & white version of the image.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64117a0-202a-49b6-b38c-c62ecf5952c2",
   "metadata": {},
   "source": [
    "### It helps in detecting lanes and lines more clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74857a3-33f2-4ebd-8993-27c9f45057f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## kernel = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2418591b-0b75-4825-9331-00ab8ab9d22f",
   "metadata": {},
   "source": [
    "### ‚ÄúUse a 5√ó5 square window to blur the image.‚Äù\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68edc9a4-bb6a-4704-a8d3-0ad181288c89",
   "metadata": {},
   "source": [
    "### We blur it to remove noise ‚Äî tiny unwanted edges or details ‚Äî before detecting the real edges like lane lines.\n",
    "\n",
    "### Without blur: too many lines\n",
    "### With blur: clean and smooth edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52c5dd8-7128-424e-b98d-f3f3356f84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    " ##   blur = cv2.GaussianBlur(gray,(kernel, kernel),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929776e6-38cf-4e9c-85b5-03c2d103f632",
   "metadata": {},
   "source": [
    "### ‚ÄúSmooth the gray image using a 5√ó5 filter, and let OpenCV decide how much to smooth.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f0af54-0435-4f47-a7ea-9fd0dddcc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## can = cv2.Canny(gray, 50, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee00257-3602-48fa-8bab-0831d6eb7e5d",
   "metadata": {},
   "source": [
    "### This line finds the edges in the image ‚Äî like lane lines, road markings, or anything with a clear boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba566467-6c9b-4040-8c64-56ac0c0c1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cv2.Canny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013ea32-ea4e-4159-a7d3-de018a4af514",
   "metadata": {},
   "source": [
    "### It‚Äôs an OpenCV function called Canny Edge Detection.\n",
    "\n",
    "### It finds the edges (sharp changes in color or brightness) in a gray or blurred image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f501b0-c46e-4217-8d60-947934ddada9",
   "metadata": {},
   "source": [
    "### Edges between 50 and 150 are kept only if they are connected to strong edges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b84863-6489-4b24-9b07-b5a1bb5180bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## return can"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec6d7b-9321-43d2-af49-02b8d1bf972e",
   "metadata": {},
   "source": [
    "### return can means: ‚ÄúSend the edge-detected image (created by Canny) back to wherever this function was called.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "830c1ca1-b241-4163-80df-1f329ae21c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##def region_of_interest(can):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0620382f-85c8-4c3d-817b-4c0d245c7fb2",
   "metadata": {},
   "source": [
    "### Only show me the part of the image where the road is, and ignore everything else (like sky, trees, cars, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "742bddd6-11e6-4046-b807-f4807199fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## height = can.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29619a8f-4ba1-4828-9819-ec2f858803a7",
   "metadata": {},
   "source": [
    "### can.shape[0] gives the height (number of rows) of the image\n",
    "\n",
    "### Example: If the image is 720 pixels tall, height=720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417afdb8-979e-43f7-8c28-adb9d5c662b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##width = can.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19ee06-9f22-4f00-8188-51a3bb6d6c54",
   "metadata": {},
   "source": [
    "### can.shape[1] gives the width (number of columns) of the image\n",
    "\n",
    "### Example: If the image is 1280 pixels wide, width = 1280\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a517d370-fd64-4f69-a65a-8166ed1ea505",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mask = np.zeros_like(can)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5445377-dfe5-4656-8a25-7c6cfdc477db",
   "metadata": {},
   "source": [
    "### This creates a black image of the same size as can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8ac456f-f970-4b3d-9fea-c254b4b96551",
   "metadata": {},
   "outputs": [],
   "source": [
    "## triangle = np.array([[\n",
    "    ## (200, height),\n",
    "   ##  (800, 350),\n",
    "    ## (1200, height),]], np.int32)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf126bf-383f-43de-ac9e-c34c2b483021",
   "metadata": {},
   "source": [
    "## This code creates a triangle shape using 3 points.\n",
    "## Image:\n",
    "\n",
    "  ##  (800, 350)\n",
    "        ‚ñ≤\n",
    "   ##  / \\\n",
    "   ## /   \\\n",
    "## (200, h) (1200, h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21d2c9f9-79c2-4717-a466-4aa83d8f22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##np.int32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d5f0c7-0bbc-44b3-9647-41f220fdd447",
   "metadata": {},
   "source": [
    "### ‚ÄúThese are integer (whole number) values.‚Äù\n",
    "\n",
    "### OpenCV needs it in this format when drawing shapes like polygons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce17633d-3ef0-42c5-b2c8-9db44646c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cv2.fillPoly(mask, triangle, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821cd23-ffa3-4d1f-941e-0dbc42dc9dde",
   "metadata": {},
   "source": [
    "### This draws and fills the triangle on the black mask\n",
    "\n",
    "### 255 means \"white\" ‚Üí the triangle area becomes white (everything else stays black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c766665-b9d3-4b8f-92ca-cfd33715a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "##masked_image = cv2.bitwise_and(can, mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f1c21-c868-4cb0-8bd4-5ee18924ffad",
   "metadata": {},
   "source": [
    "### Only keep the edges that fall inside this triangle (the road area).‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd3b74f-8f47-4577-8f47-39704d1f283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f226a48-fff6-4c22-82ca-76099fd5ca57",
   "metadata": {},
   "source": [
    "### This gives back the new image ‚Äî only showing the triangle region with edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e28c7d7d-d1ad-4ec1-a22c-21be2d2a7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## def houghLines(cropped_canny):\n",
    "   ## return cv2.HoughLinesP(cropped_canny, 2, np.pi/180, 100, \n",
    "       ## np.array([]), minLineLength=40, maxLineGap=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ff09f-d9d6-4629-b9c3-f0cc24c9fabd",
   "metadata": {},
   "source": [
    "### This function finds straight lines from the edge image (the one with only the road area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e26ff1f-2099-4fd5-9f2e-dc968a354299",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cv2.HoughLinesP(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588dd41a-fa9d-4271-a40b-ce575b821101",
   "metadata": {},
   "source": [
    "### This is an OpenCV function that detects straight lines in an image using something called the Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68d1c72a-453d-483c-97a3-cd3cb76fcf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cropped_canny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8bfaf-6ba3-45f5-8b25-cb44152db8c5",
   "metadata": {},
   "source": [
    "### This is the edge image, but only the region of interest (triangle part)\n",
    "\n",
    "### We give this to the function to look for straight lines in that area\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60646f1a-1c64-4ef9-81be-271160a55c73",
   "metadata": {},
   "source": [
    "### 2 means ‚Äúlook for lines with steps of 2 pixels‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00166831-ab1f-4b37-88b5-12ba97a69a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## np.pi/180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37408ff3-fa93-4c32-9d75-0d7872b593d0",
   "metadata": {},
   "source": [
    "### This is the angle resolution in radians.\n",
    "\n",
    "### It means: ‚Äúcheck every 1 degree‚Äù (because œÄ/180 ‚âà 1¬∞)\n",
    "\n",
    "### So, the computer looks in small angle steps to find lines pointing in all directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87efd730-481f-42e9-a591-82bada5c4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6cb09-b82b-456c-8c3f-244a239f2c30",
   "metadata": {},
   "source": [
    "### This is the threshold.\n",
    "\n",
    "### It means: \"Only keep lines that have 100 or more edge points on them.\"\n",
    "\n",
    "### A higher number = only strong, clear lines will be detected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c409a251-a9c3-4887-9d1a-a19db1c0741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5cad38-b250-4248-a1bb-874c3ecf73ba",
   "metadata": {},
   "source": [
    "### This is just a placeholder for older OpenCV versions that expect this input.\n",
    "\n",
    "### It‚Äôs like saying: \"No extra parameters.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "839caab6-d817-4392-aeb5-ee0c2b8a0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##minLineLength=40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53339b27-ceb2-4392-9261-019ed93e9115",
   "metadata": {},
   "source": [
    "### This tells the computer: \"Ignore any lines shorter than 40 pixels.\"\n",
    "\n",
    "### We don‚Äôt want tiny, noisy lines ‚Äî just the long ones like lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8c7cbc9-a50e-4ce8-a46b-047d0c193d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "##maxLineGap=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff8d57-2745-484d-a2c7-dc652f8cf6ef",
   "metadata": {},
   "source": [
    "### If two line segments are less than 5 pixels apart, connect them into one single line\n",
    "\n",
    "### Useful for broken or dashed lane lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1556131e-8280-4f4c-8018-fc7b34a7f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##def addWeighted(frame, line_image):\n",
    "    ##return cv2.addWeighted(frame, 0.8, line_image, 1, 1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177399bb-5017-4526-b4c2-2d7eb0ff5171",
   "metadata": {},
   "source": [
    "### You have a photo of a road (frame)\n",
    "\n",
    "### You draw red lines on a transparent sheet (line_image)\n",
    "\n",
    "### You place the transparent sheet on top of the photo\n",
    "\n",
    "### That's exactly what cv2.addWeighted() does! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60df7e32-8926-4449-9b58-d5f12486fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9498ee5-7fa2-4e74-b945-5efd3a4541cf",
   "metadata": {},
   "source": [
    "### This means we keep 80% of the original image brightness\n",
    "\n",
    "### Helps the lane lines stand out more clearly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3df4a-553f-4552-aea9-1ba99a0501fa",
   "metadata": {},
   "source": [
    "### first 1:This means we keep 100% of the line image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007f83d-c954-485b-8e0d-050d12008b98",
   "metadata": {},
   "source": [
    "### second 1:This just adds a little brightness\n",
    "\n",
    "### Think of it like a final touch of light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6e13cac-f782-478c-ba50-9de97b08de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## def display_lines(img,lines):\n",
    "    ## line_image = np.zeros_like(img)\n",
    "    ## if lines is not None:\n",
    "        ## for line in lines:\n",
    "            ## for x1, y1, x2, y2 in line:\n",
    "                ## cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),10)\n",
    "    ## return line_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7c073-b070-47a0-bf83-6fb6a02c756a",
   "metadata": {},
   "source": [
    "### To draw red lines on a blank image wherever lane lines were detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd48f401-49b6-4886-a89d-8651ec1bf8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##line_image = np.zeros_like(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78b536-3e63-4db1-97c8-614bfb45c8e1",
   "metadata": {},
   "source": [
    "### A blank canvas where we will paint the lane lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86e9317f-dafd-4fbb-b78b-8642bfa86fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##if lines is not None:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7608b-9b96-41b1-aeb4-c4d35c5e9ed6",
   "metadata": {},
   "source": [
    "### Just checking that we actually got some lines\n",
    "\n",
    "### If no lines were found, we skip drawing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "520d7fbc-1a76-4f2b-8278-a5ef2b31019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for line in lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a44b30-198e-4b73-9c8d-ae2e420488ee",
   "metadata": {},
   "source": [
    "### lines is a list of line coordinates\n",
    "\n",
    "### Each line is something like: [[x1, y1, x2, y2]]\n",
    "\n",
    "### These are the start and end points of the line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72f6f4c6-de9d-45d9-b036-5a9f3f5410c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##for x1, y1, x2, y2 in line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b52e2-c5b8-4a6c-9688-ad6c3ec01221",
   "metadata": {},
   "source": [
    "### We unpack the values from that line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e81b7110-bb92-4971-a802-b707715fad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cv2.line(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c998ba-58f8-41ba-bf05-3fc47225cf85",
   "metadata": {},
   "source": [
    "## This is the actual drawing command:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69a6b8-4beb-47ac-9789-e9676e93722b",
   "metadata": {},
   "source": [
    "### line_image : The image we are drawing on (black background)\n",
    "### (x1, y1), (x2, y2)\t:Start and end points of the line\n",
    "### (0, 0, 255):\tColor: this is red in BGR format\n",
    "### 10\t:Thickness of the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "610c3edc-7b94-4e1b-9f0c-3f748bda3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "##return line_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadbdf6b-db83-4369-aaa6-cb3399b6b700",
   "metadata": {},
   "source": [
    "###  return the image that now has all the red lines drawn on it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b30a78a-0c50-475c-914c-037f0f93ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def make_points(image, line):\n",
    "    #slope, intercept = line\n",
    "    #y1 = int(image.shape[0])\n",
    "    #y2 = int(y1*3.0/5)      \n",
    "    #x1 = int((y1 - intercept)/slope)\n",
    "    #x2 = int((y2 - intercept)/slope)\n",
    "    #return [[x1, y1, x2, y2]]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1a82e-3585-4e82-9622-5842046ca0ef",
   "metadata": {},
   "source": [
    "### This function takes a line in math format (slope and intercept from y = mx + b) and converts it into pixel coordinates that can be drawn on the image.\n",
    "\n",
    "### So instead of saying:\n",
    "\n",
    "### ‚ÄúThe line is y = 0.5x + 10‚Äù\n",
    "\n",
    "### We say:\n",
    "\n",
    "### ‚ÄúDraw a line from (x1, y1) to (x2, y2)‚Äù\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ce6fae6-1084-4e96-9dd0-069d8f528f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "##slope, intercept = line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755f20e-e78b-45ac-badc-f6d2d16d6e50",
   "metadata": {},
   "source": [
    "### Every straight line has a slope (tilt) and an intercept (where it hits y-axis)\n",
    "\n",
    "### This line came from the average_slope_intercept() function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ece7480-ce5d-407e-805d-0c35302fe8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##y1 = int(image.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7996b-cc8a-404d-b821-32d2989b48e6",
   "metadata": {},
   "source": [
    "### This is the bottom of the image (height)\n",
    "\n",
    "### We‚Äôll start our line from the bottom of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4274686e-2341-4a9d-b09e-5deaf628d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##y2 = int(y1 * 3.0 / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b57afc-7cce-4106-9aa2-c551ba497d91",
   "metadata": {},
   "source": [
    "### This is a bit higher than halfway up the image\n",
    "\n",
    "### So we don‚Äôt draw lines all the way to the top, just partway up (where lanes usually end in the camera view)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64cba334-0298-48d2-b380-4e9088fbd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##x1 = int((y1 - intercept) / slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e7b65-7856-4dec-8a14-29c90bc4cb6d",
   "metadata": {},
   "source": [
    "### From the formula y = mx + b ‚Üí rearranged as:\n",
    "### x = (y - b) / m\n",
    "### This calculates the x position where the line hits the bottom (y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ede844e-7381-448b-a2bb-7372f789f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##x2 = int((y2 - intercept) / slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526e646-966c-42e1-89b5-bf39ae56d392",
   "metadata": {},
   "source": [
    "### same thing, but for the higher point y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26299a98-eb12-419e-be9e-86d3308a9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### return [[x1, y1, x2, y2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e928f-e508-410a-a6fa-b4c9e058334e",
   "metadata": {},
   "source": [
    "### We return a line in this format: [[start_x, start_y, end_x, end_y]]\n",
    "\n",
    "### This can be directly used for drawing a line on the image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50a5e7b1-777f-4242-b2a0-1c6e05b2cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def average_slope_intercept(image, lines):\n",
    "    #left_fit    = []\n",
    "    #right_fit   = []\n",
    "    #if lines is None:\n",
    "        #return None\n",
    "    #for line in lines:\n",
    "        #for x1, y1, x2, y2 in line:\n",
    "            #fit = np.polyfit((x1,x2), (y1,y2), 1)\n",
    "            #slope = fit[0]\n",
    "            #intercept = fit[1]\n",
    "            #if slope < 0: \n",
    "                #left_fit.append((slope, intercept))\n",
    "            #else:\n",
    "                #right_fit.append((slope, intercept))\n",
    "    #left_fit_average  = np.average(left_fit, axis=0)\n",
    "    #right_fit_average = np.average(right_fit, axis=0)\n",
    "    #left_line  = make_points(image, left_fit_average)\n",
    "    #right_line = make_points(image, right_fit_average)\n",
    "    #averaged_lines = [left_line, right_line]\n",
    "    #return averaged_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7091e-72bb-407e-b63e-3c681be721f8",
   "metadata": {},
   "source": [
    "#### We want to take lots of small lines (from Hough Transform), figure out which ones belong to the left lane and which ones belong to the right lane, then draw just one clean line for each lane.\n",
    "\n",
    "#### Imagine you saw many little chalk lines drawn on a road. Some are wiggly, some are short. We want to look at them and say:\n",
    "\n",
    "### ‚ÄúLet‚Äôs draw one big, straight, neat red line on the left... and one on the right.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6fce596-bd84-477f-9383-b173544e0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "##def average_slope_intercept(image, lines):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1e80fe-7dd5-41fe-82c9-3fe68e5b2a15",
   "metadata": {},
   "source": [
    "### We're going to clean up the lines using math!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da9932a7-2099-400c-84c4-a1283e462721",
   "metadata": {},
   "outputs": [],
   "source": [
    "##left_fit = []\n",
    "##right_fit = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bef71a-f1b2-4414-bc2d-e263f4a566f7",
   "metadata": {},
   "source": [
    "### We will separate the lines into left and right buckets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0069f6e5-a88c-4c29-a9ac-76e4294dfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if lines is None:\n",
    "    ##return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebec5bc-642b-4f46-8604-5031925e25d0",
   "metadata": {},
   "source": [
    "### If the computer didn‚Äôt find any lines, we stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b23a6293-b260-4236-ad8c-9220404e1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for line in lines:\n",
    "    #for x1, y1, x2, y2 in line:\n",
    "        #fit = np.polyfit((x1,x2), (y1,y2), 1)\n",
    "        #slope = fit[0]\n",
    "        #intercept = fit[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd446fb-7a10-4a3d-a21f-79234492abdc",
   "metadata": {},
   "source": [
    "## Go through each line and calculate its slope and intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862f572-9ffd-4bec-b7f1-7156edee926a",
   "metadata": {},
   "source": [
    "## Put the line in the correct bucket\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecd9467a-7945-43cb-9bb3-9c5399383efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if slope < 0: \n",
    "   #left_fit.append((slope, intercept))\n",
    "#else:\n",
    "   # right_fit.append((slope, intercept))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9dcd0-b0c2-48f3-b20a-641c0df2c90d",
   "metadata": {},
   "source": [
    "### If the line is leaning left (slope is negative), it‚Äôs a left lane\n",
    "\n",
    "### If it‚Äôs leaning right (slope is positive), it‚Äôs a right lane\n",
    "\n",
    "### We save the slope and intercept in the correct list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23910b35-440a-4559-b2d8-41a2a9bf3483",
   "metadata": {},
   "source": [
    "## Average the slopes and intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cd31bbc-f745-4dee-9b71-3192280739a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#left_fit_average = np.average(left_fit, axis=0)\n",
    "#right_fit_average = np.average(right_fit, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844df656-a971-4716-ae1b-9ce700bd7196",
   "metadata": {},
   "source": [
    "### We use the earlier function make_points() to convert math back into:\n",
    "\n",
    "### start and end x, y points\n",
    "\n",
    "### So now we can draw them!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4ec6d34-f861-4394-9690-2621971491f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#left_line = make_points(image, left_fit_average)\n",
    "#right_line = make_points(image, right_fit_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c6e98-5113-4f78-8b09-caac44810e07",
   "metadata": {},
   "source": [
    "## Return both clean lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04abe5ea-bd0c-4292-b660-be4b4c25f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#averaged_lines = [left_line, right_line]\n",
    "#return averaged_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901d61a-8fcd-457a-aa27-36775cd5afb1",
   "metadata": {},
   "source": [
    "#### We now have two clean red lines that show the left and right lanes. Perfect for guiding a self-driving car or just understanding the road better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeebb85-a796-4681-8109-5e2df6cd3aac",
   "metadata": {},
   "source": [
    "## You had this messy road full of tiny lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aaa4e0-bdf5-4efe-8a8c-ca639655b37a",
   "metadata": {},
   "source": [
    "### \\\\ \\  \\\\     //   // ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53004fc9-7028-4a19-8c59-c20c261a1e11",
   "metadata": {},
   "source": [
    "### Now, you're turning it into just:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba6aa9-1031-4bcf-bdfd-1bf25dad2892",
   "metadata": {},
   "source": [
    "  \"\"\"  \\           /\n",
    "   \"\"\"\" \\         /\n",
    "    \"\"\"\" \\       /\n",
    "     \"\"\"\" ------- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c773f3f-164f-4a18-9b61-0e0455ee95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(\"test1.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446aa773-cf1c-4df0-8042-e09bc3a1fbf2",
   "metadata": {},
   "source": [
    "### cap is your video player\n",
    "\n",
    "### This lets you play the video frame-by-frame (1 image at a time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03ae2d-2ac7-4de9-baf9-6231325b45a1",
   "metadata": {},
   "source": [
    "## Loop over every frame in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc076dbe-84e6-458a-a992-720a8a4601dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#while(cap.isOpened()):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba40a4-15c5-499b-8fb1-bd5338dea653",
   "metadata": {},
   "source": [
    "###  ‚ÄúKeep playing the video as long as it's open and working.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39b5f2-dd22-40e1-9373-6ee3cb75d82e",
   "metadata": {},
   "source": [
    "## Read each video frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67c36b32-d0fb-45ef-a077-8e6533e9ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, frame = cap.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480856b-4748-4bc2-bcaf-cc004099615b",
   "metadata": {},
   "source": [
    "### This captures one single image frame from the video.\n",
    "\n",
    "### Each video is just many pictures shown quickly, like a flipbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6decb-fb88-445a-90ac-0fa1d69cd3c2",
   "metadata": {},
   "source": [
    "## Apply Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "442454a3-e924-4bd3-8b54-9871019c002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#canny_image = can(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc8297-ccac-48f1-beed-9ca2d00d86a0",
   "metadata": {},
   "source": [
    "### You send the frame to the can() function ‚Äî which:\n",
    "\n",
    "### turns the image to black & white\n",
    "\n",
    "### blurs it to reduce noise\n",
    "\n",
    "### detects sharp edges (like road lane lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a74dec-1c0f-4051-b3b1-b2af77886657",
   "metadata": {},
   "source": [
    "## Focus only on the road area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2f5780f-0573-41d8-abf3-59c2767338b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropped_canny = region_of_interest(canny_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75a456-1da0-4a76-aaab-54c49d29d1e7",
   "metadata": {},
   "source": [
    "### This removes extra stuff (like sky, trees, etc.) and keeps only the triangle-shaped road area.\n",
    "\n",
    "### It‚Äôs like saying: ‚ÄúLook only where the lanes should be.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9e9f0-5d86-4595-99c0-21e289f381c0",
   "metadata": {},
   "source": [
    "## Detect possible lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b306944c-b002-4a9b-ad2a-fb7cf99ebe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines = houghLines(cropped_canny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7601750-3072-40ea-ba51-f554f5d51b1f",
   "metadata": {},
   "source": [
    "### This tries to find lines in the edge image using Hough Line Transform. It gives us a list of short lines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100c806-c4bf-4d70-a0b0-7a7971eb4509",
   "metadata": {},
   "source": [
    "## Clean up the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aac50ee1-6783-42e8-acab-2b81b1a2b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#averaged_lines = average_slope_intercept(frame, lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322d8d8-9437-41a6-a2c0-1cee9cb5cf9d",
   "metadata": {},
   "source": [
    "### Takes all those tiny lines and finds one clean left line and one clean right line.\n",
    "\n",
    "### Like removing messy scribbles and drawing two neat lines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d5b0f7-0bb3-4fad-ae04-9dc2a9e66d3d",
   "metadata": {},
   "source": [
    "## Turn math lines into a drawing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37500952-a98c-4557-929b-8b0c8b44c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "##line_image = display_lines(frame, averaged_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02691c-4eed-4f40-9041-15cac40c05dc",
   "metadata": {},
   "source": [
    "### This draws red lines on a blank image based on the points from above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0a90c-6fae-40ca-b402-41a6c85504c5",
   "metadata": {},
   "source": [
    "## Mix the original frame with the red lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a30fb729-2a1e-42c1-a93f-b4f87b268944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combo_image = addWeighted(frame, line_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8355ff-d266-4cdb-bc4e-6a066003f5b3",
   "metadata": {},
   "source": [
    "### Now we overlay the red line drawing on top of the original video frame.\n",
    "\n",
    "### So we see the road + the lanes clearly marked \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57720fbb-8033-47d5-b9a2-db2d6b1d663f",
   "metadata": {},
   "source": [
    "### Show the final result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9c45a9c-42dd-49d5-b30b-24ad2bfeec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imshow(\"result\", combo_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaed4ce3-1ce4-4f07-a104-5ea439db58ac",
   "metadata": {},
   "source": [
    "## Break if the user presses ‚Äòq‚Äô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "361b7805-b6a9-4c09-8d01-94f709e479e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5132f-688a-4b0b-bda0-ac4008cac529",
   "metadata": {},
   "source": [
    "### Waits 1 millisecond to check:\n",
    "\n",
    "### \"Did someone press the Q key?\"\n",
    "\n",
    "### If yes ‚Äî we stop the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c79d7-d5e2-452a-bc04-6633a50f0948",
   "metadata": {},
   "source": [
    " ## Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c356ec-2477-4a68-9c03-17bd64af3c68",
   "metadata": {},
   "source": [
    "### cap.release(): Stop using the video file\n",
    "\n",
    " ### cv2.destroyAllWindows(): Close all image windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549a9ae-9ada-41ea-83ec-0208347e6138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
